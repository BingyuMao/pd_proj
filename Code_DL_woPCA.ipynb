{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3079f6a",
   "metadata": {},
   "source": [
    "## Deep learning models\n",
    "#### Import packages, load data and define necussary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3bad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c47b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read the training dataset after resampling and standardization\n",
    "df = pd.read_csv('train_scaled.smote.csv')\n",
    "\n",
    "#remove class and id\n",
    "features = list(df.columns.values)\n",
    "features.remove('class')\n",
    "features.remove('id')\n",
    "\n",
    "X = df[features]\n",
    "y = df['class']\n",
    "#split to train and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.7)\n",
    "\n",
    "#set up the test set\n",
    "df_test = pd.read_csv('test_scaled.csv')\n",
    "features_test = list(df_test.columns.values)\n",
    "features_test.remove('class')\n",
    "features_test.remove('id')\n",
    "\n",
    "X_test = df_test[features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a5d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function for sensitivity, specificity and f1 score\n",
    "def ss(X, y, m):\n",
    "    cm = confusion_matrix(y, np.rint(m.predict(X)))\n",
    "    sen = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "    spe = cm[1][1] / (cm[1][0] + cm[1][1])\n",
    "    prec = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "    f1 = 2 * prec * sen / (prec + sen)\n",
    "    return sen, spe, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448115e",
   "metadata": {},
   "source": [
    "#### Define and train the data on three different models\n",
    "\n",
    "The first model is a simple neural network with regular densely-connected NN layers. The second model is GRU (a type of RNN model) and the third model is another RNN model called LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8611f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3/3 [==============================] - 2s 274ms/step - loss: 0.8266 - accuracy: 0.5891 - val_loss: 1.3386 - val_accuracy: 0.3939\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7173 - accuracy: 0.6744 - val_loss: 0.8186 - val_accuracy: 0.5758\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5743 - accuracy: 0.7907 - val_loss: 0.6450 - val_accuracy: 0.6970\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3916 - accuracy: 0.8605 - val_loss: 0.5222 - val_accuracy: 0.7576\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2895 - accuracy: 0.9070 - val_loss: 0.5724 - val_accuracy: 0.6667\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2632 - accuracy: 0.8605 - val_loss: 0.5057 - val_accuracy: 0.6970\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1910 - accuracy: 0.9070 - val_loss: 0.5369 - val_accuracy: 0.7576\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.2125 - accuracy: 0.8992 - val_loss: 0.5451 - val_accuracy: 0.7879\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1559 - accuracy: 0.9225 - val_loss: 0.5395 - val_accuracy: 0.8485\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1168 - accuracy: 0.9535 - val_loss: 0.5712 - val_accuracy: 0.7879\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1076 - accuracy: 0.9380 - val_loss: 0.5608 - val_accuracy: 0.8485\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0896 - accuracy: 0.9612 - val_loss: 0.5328 - val_accuracy: 0.8485\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0777 - accuracy: 0.9845 - val_loss: 0.5083 - val_accuracy: 0.8485\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0629 - accuracy: 0.9845 - val_loss: 0.4963 - val_accuracy: 0.8788\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0556 - accuracy: 0.9845 - val_loss: 0.4932 - val_accuracy: 0.8788\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0492 - accuracy: 0.9922 - val_loss: 0.5082 - val_accuracy: 0.8485\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0443 - accuracy: 0.9922 - val_loss: 0.5236 - val_accuracy: 0.8182\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0438 - accuracy: 0.9845 - val_loss: 0.5274 - val_accuracy: 0.8485\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0439 - accuracy: 0.9845 - val_loss: 0.5387 - val_accuracy: 0.8182\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0348 - accuracy: 0.9845 - val_loss: 0.5595 - val_accuracy: 0.8182\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.5693 - val_accuracy: 0.8182\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 0.5638 - val_accuracy: 0.8182\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.5401 - val_accuracy: 0.8182\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.5192 - val_accuracy: 0.8485\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.5044 - val_accuracy: 0.8485\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.4953 - val_accuracy: 0.8788\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.4889 - val_accuracy: 0.8788\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.4861 - val_accuracy: 0.8788\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.4929 - val_accuracy: 0.8788\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.5189 - val_accuracy: 0.8485\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.5438 - val_accuracy: 0.8182\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.5621 - val_accuracy: 0.8182\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.5739 - val_accuracy: 0.8182\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.5794 - val_accuracy: 0.8182\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.5799 - val_accuracy: 0.8182\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.5776 - val_accuracy: 0.8182\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.5738 - val_accuracy: 0.8182\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.5701 - val_accuracy: 0.8182\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.5659 - val_accuracy: 0.8182\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.5619 - val_accuracy: 0.8182\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.5583 - val_accuracy: 0.8182\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.5551 - val_accuracy: 0.8182\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.5524 - val_accuracy: 0.8182\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.5503 - val_accuracy: 0.8182\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.5485 - val_accuracy: 0.8182\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.5468 - val_accuracy: 0.8182\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.5460 - val_accuracy: 0.8182\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.5462 - val_accuracy: 0.8182\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.5451 - val_accuracy: 0.8182\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5424 - val_accuracy: 0.8485\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5431 - val_accuracy: 0.8485\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5494 - val_accuracy: 0.8485\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5545 - val_accuracy: 0.8485\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5579 - val_accuracy: 0.8485\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5597 - val_accuracy: 0.8485\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5600 - val_accuracy: 0.8485\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5592 - val_accuracy: 0.8485\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 0.5577 - val_accuracy: 0.8485\n",
      "Epoch 59/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.5566 - val_accuracy: 0.8485\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.5562 - val_accuracy: 0.8485\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.5554 - val_accuracy: 0.8485\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.5545 - val_accuracy: 0.8485\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5533 - val_accuracy: 0.8485\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5521 - val_accuracy: 0.8485\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5510 - val_accuracy: 0.8485\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5512 - val_accuracy: 0.8485\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5535 - val_accuracy: 0.8485\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5549 - val_accuracy: 0.8485\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5555 - val_accuracy: 0.8485\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5553 - val_accuracy: 0.8485\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5544 - val_accuracy: 0.8485\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5536 - val_accuracy: 0.8485\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5532 - val_accuracy: 0.8485\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5530 - val_accuracy: 0.8788\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5535 - val_accuracy: 0.8788\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5538 - val_accuracy: 0.8485\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5539 - val_accuracy: 0.8485\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5540 - val_accuracy: 0.8485\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5538 - val_accuracy: 0.8485\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5500 - val_accuracy: 0.8485\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5449 - val_accuracy: 0.8485\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5409 - val_accuracy: 0.8485\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5380 - val_accuracy: 0.8485\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5369 - val_accuracy: 0.8485\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 0.5363 - val_accuracy: 0.8485\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5349 - val_accuracy: 0.8485\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5320 - val_accuracy: 0.8485\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5288 - val_accuracy: 0.8485\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5262 - val_accuracy: 0.8485\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5242 - val_accuracy: 0.8485\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5224 - val_accuracy: 0.8485\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5211 - val_accuracy: 0.8485\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5205 - val_accuracy: 0.8485\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5201 - val_accuracy: 0.8485\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5203 - val_accuracy: 0.8485\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5206 - val_accuracy: 0.8485\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5209 - val_accuracy: 0.8485\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5211 - val_accuracy: 0.8485\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5212 - val_accuracy: 0.8485\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.5214 - val_accuracy: 0.8485\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5217 - val_accuracy: 0.8485\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5226 - val_accuracy: 0.8485\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5242 - val_accuracy: 0.8788\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5256 - val_accuracy: 0.8788\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5270 - val_accuracy: 0.8788\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5285 - val_accuracy: 0.8788\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5296 - val_accuracy: 0.9091\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5294 - val_accuracy: 0.9091\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5277 - val_accuracy: 0.9091\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5270 - val_accuracy: 0.9091\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5276 - val_accuracy: 0.9091\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5285 - val_accuracy: 0.9091\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5294 - val_accuracy: 0.9091\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5307 - val_accuracy: 0.9091\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5319 - val_accuracy: 0.9091\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5329 - val_accuracy: 0.9091\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.5336 - val_accuracy: 0.9091\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5340 - val_accuracy: 0.9091\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5345 - val_accuracy: 0.9091\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5350 - val_accuracy: 0.9091\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5357 - val_accuracy: 0.9091\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5363 - val_accuracy: 0.9091\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5367 - val_accuracy: 0.9091\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5370 - val_accuracy: 0.9091\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5373 - val_accuracy: 0.9091\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5375 - val_accuracy: 0.9091\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5378 - val_accuracy: 0.9091\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5380 - val_accuracy: 0.9091\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5383 - val_accuracy: 0.9091\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5388 - val_accuracy: 0.9091\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5396 - val_accuracy: 0.9091\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5404 - val_accuracy: 0.9091\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5413 - val_accuracy: 0.9091\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5420 - val_accuracy: 0.9091\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5426 - val_accuracy: 0.9091\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5430 - val_accuracy: 0.9091\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5432 - val_accuracy: 0.9091\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5436 - val_accuracy: 0.9091\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5442 - val_accuracy: 0.9091\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5450 - val_accuracy: 0.9091\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5457 - val_accuracy: 0.9091\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5457 - val_accuracy: 0.9091\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5458 - val_accuracy: 0.9091\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5460 - val_accuracy: 0.9091\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5462 - val_accuracy: 0.9091\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5465 - val_accuracy: 0.9091\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5468 - val_accuracy: 0.9091\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5470 - val_accuracy: 0.9091\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5473 - val_accuracy: 0.9091\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.5476 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x283e810cb80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the model\n",
    "#this is a Neural Network which four layers. \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(753,)), #confirm the input shape\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu), \n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid), \n",
    "])\n",
    "\n",
    "#RMSprop, Adam, Adamax, Nadam\n",
    "opt = keras.optimizers.Adamax(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9607bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0673 - accuracy: 0.8413\n",
      "Valid accuracy: 0.841269850730896\n",
      "AUC on validation set: 0.9032754759238522\n",
      "Sencitivity for neural network: 0.898936170212766\n",
      "Specifity for neural network: 0.7842105263157895\n",
      "F1 score for neural network: 0.8492462311557789\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on validation set\n",
    "valid_loss_nn, valid_acc_nn = model.evaluate(X_valid, y_valid)\n",
    "print('Valid accuracy:', valid_acc_nn)\n",
    "\n",
    "#for roc plot\n",
    "y_pre_nn = model.predict(X_valid).ravel()\n",
    "fpr_nn, tpr_nn, thresholds_nn = roc_curve(y_valid, y_pre_nn)\n",
    "auc_nn = auc(fpr_nn, tpr_nn)\n",
    "print(\"AUC on validation set:\", auc_nn)\n",
    "\n",
    "#sensitivity, specificity and f1 score\n",
    "sen_nn, spe_nn, f1_nn = ss(X_valid, y_valid, model)\n",
    "print(\"Sencitivity for neural network:\", sen_nn)\n",
    "print(\"Specifity for neural network:\", spe_nn)\n",
    "print(\"F1 score for neural network:\", f1_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a15dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadb8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 1, 753)\n",
    "X_valid = X_valid.values.reshape(-1, 1, 753)\n",
    "X_test  = X_test.values.reshape(-1, 1, 753)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d84706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6932 - accuracy: 0.4884 - val_loss: 0.6912 - val_accuracy: 0.6364\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6884 - accuracy: 0.7442 - val_loss: 0.6865 - val_accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6825 - accuracy: 0.7054 - val_loss: 0.6786 - val_accuracy: 0.5758\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6726 - accuracy: 0.7209 - val_loss: 0.6811 - val_accuracy: 0.6364\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6721 - accuracy: 0.7829 - val_loss: 0.6787 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6658 - accuracy: 0.7597 - val_loss: 0.6729 - val_accuracy: 0.6364\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6595 - accuracy: 0.7519 - val_loss: 0.6741 - val_accuracy: 0.6061\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6575 - accuracy: 0.7829 - val_loss: 0.6725 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6546 - accuracy: 0.7752 - val_loss: 0.6691 - val_accuracy: 0.6970\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6509 - accuracy: 0.8295 - val_loss: 0.6659 - val_accuracy: 0.7273\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6462 - accuracy: 0.8372 - val_loss: 0.6637 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6425 - accuracy: 0.7907 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6347 - accuracy: 0.8217 - val_loss: 0.6534 - val_accuracy: 0.6364\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6343 - accuracy: 0.8062 - val_loss: 0.6501 - val_accuracy: 0.6364\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6293 - accuracy: 0.8372 - val_loss: 0.6448 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6224 - accuracy: 0.8372 - val_loss: 0.6466 - val_accuracy: 0.7273\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6186 - accuracy: 0.8682 - val_loss: 0.6394 - val_accuracy: 0.6970\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6113 - accuracy: 0.8682 - val_loss: 0.6388 - val_accuracy: 0.7576\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6064 - accuracy: 0.8760 - val_loss: 0.6342 - val_accuracy: 0.7576\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5993 - accuracy: 0.8682 - val_loss: 0.6302 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5950 - accuracy: 0.8682 - val_loss: 0.6240 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5881 - accuracy: 0.8682 - val_loss: 0.6171 - val_accuracy: 0.6970\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5790 - accuracy: 0.8682 - val_loss: 0.6264 - val_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5842 - accuracy: 0.8062 - val_loss: 0.6178 - val_accuracy: 0.6970\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5701 - accuracy: 0.8450 - val_loss: 0.6099 - val_accuracy: 0.7576\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5650 - accuracy: 0.9225 - val_loss: 0.6020 - val_accuracy: 0.7576\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5523 - accuracy: 0.9380 - val_loss: 0.5936 - val_accuracy: 0.7576\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5425 - accuracy: 0.9302 - val_loss: 0.5877 - val_accuracy: 0.7576\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5328 - accuracy: 0.9690 - val_loss: 0.5898 - val_accuracy: 0.6061\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5314 - accuracy: 0.9070 - val_loss: 0.5852 - val_accuracy: 0.7273\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5260 - accuracy: 0.9457 - val_loss: 0.5812 - val_accuracy: 0.7576\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5181 - accuracy: 0.9690 - val_loss: 0.5800 - val_accuracy: 0.7273\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5117 - accuracy: 0.9845 - val_loss: 0.5761 - val_accuracy: 0.7273\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5047 - accuracy: 0.9922 - val_loss: 0.5703 - val_accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4968 - accuracy: 0.9922 - val_loss: 0.5770 - val_accuracy: 0.7273\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4928 - accuracy: 0.9922 - val_loss: 0.5701 - val_accuracy: 0.7273\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4844 - accuracy: 0.9922 - val_loss: 0.6049 - val_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4949 - accuracy: 0.9457 - val_loss: 0.5672 - val_accuracy: 0.7273\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4799 - accuracy: 0.9922 - val_loss: 0.5630 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4686 - accuracy: 0.9922 - val_loss: 0.5553 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4625 - accuracy: 0.9922 - val_loss: 0.5397 - val_accuracy: 0.7576\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4624 - accuracy: 0.9690 - val_loss: 0.5433 - val_accuracy: 0.7576\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4506 - accuracy: 0.9922 - val_loss: 0.5402 - val_accuracy: 0.7576\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4469 - accuracy: 0.9922 - val_loss: 0.5360 - val_accuracy: 0.7576\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4408 - accuracy: 0.9922 - val_loss: 0.5359 - val_accuracy: 0.7576\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4347 - accuracy: 0.9922 - val_loss: 0.5346 - val_accuracy: 0.7576\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4295 - accuracy: 0.9922 - val_loss: 0.5307 - val_accuracy: 0.7576\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4266 - accuracy: 0.9922 - val_loss: 0.5312 - val_accuracy: 0.7576\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4202 - accuracy: 0.9922 - val_loss: 0.5244 - val_accuracy: 0.7879\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4150 - accuracy: 0.9922 - val_loss: 0.5170 - val_accuracy: 0.7879\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4069 - accuracy: 0.9922 - val_loss: 0.5198 - val_accuracy: 0.7576\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4008 - accuracy: 0.9922 - val_loss: 0.5245 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3947 - accuracy: 0.9922 - val_loss: 0.5218 - val_accuracy: 0.7879\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3887 - accuracy: 0.9922 - val_loss: 0.5191 - val_accuracy: 0.7879\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3823 - accuracy: 0.9922 - val_loss: 0.5136 - val_accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3765 - accuracy: 0.9922 - val_loss: 0.5136 - val_accuracy: 0.7576\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3709 - accuracy: 0.9922 - val_loss: 0.5093 - val_accuracy: 0.7576\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3644 - accuracy: 0.9922 - val_loss: 0.5060 - val_accuracy: 0.7576\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3659 - accuracy: 0.9922 - val_loss: 0.4944 - val_accuracy: 0.7879\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3612 - accuracy: 0.9922 - val_loss: 0.4942 - val_accuracy: 0.8485\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3570 - accuracy: 0.9922 - val_loss: 0.4914 - val_accuracy: 0.8485\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3526 - accuracy: 0.9922 - val_loss: 0.4940 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3475 - accuracy: 0.9922 - val_loss: 0.4878 - val_accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3418 - accuracy: 0.9922 - val_loss: 0.4789 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3371 - accuracy: 0.9922 - val_loss: 0.4778 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3321 - accuracy: 0.9922 - val_loss: 0.4728 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3274 - accuracy: 0.9922 - val_loss: 0.4716 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3222 - accuracy: 0.9922 - val_loss: 0.4735 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3170 - accuracy: 0.9922 - val_loss: 0.4675 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3121 - accuracy: 0.9922 - val_loss: 0.4587 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3062 - accuracy: 0.9922 - val_loss: 0.4552 - val_accuracy: 0.8485\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3018 - accuracy: 0.9922 - val_loss: 0.4495 - val_accuracy: 0.8485\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2955 - accuracy: 0.9922 - val_loss: 0.4475 - val_accuracy: 0.8485\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2901 - accuracy: 0.9922 - val_loss: 0.4638 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.2843 - accuracy: 0.9922 - val_loss: 0.4551 - val_accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2789 - accuracy: 0.9922 - val_loss: 0.4461 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2748 - accuracy: 0.9922 - val_loss: 0.4250 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.2693 - accuracy: 0.9922 - val_loss: 0.4538 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2631 - accuracy: 0.9922 - val_loss: 0.4465 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2579 - accuracy: 0.9922 - val_loss: 0.4549 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.2525 - accuracy: 0.9922 - val_loss: 0.4492 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2474 - accuracy: 0.9922 - val_loss: 0.4457 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2429 - accuracy: 0.9922 - val_loss: 0.4416 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2389 - accuracy: 0.9922 - val_loss: 0.4394 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2346 - accuracy: 0.9922 - val_loss: 0.4362 - val_accuracy: 0.8485\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.2302 - accuracy: 0.9922 - val_loss: 0.4549 - val_accuracy: 0.7879\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.2251 - accuracy: 0.9922 - val_loss: 0.4532 - val_accuracy: 0.7879\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2213 - accuracy: 0.9922 - val_loss: 0.4674 - val_accuracy: 0.7879\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2177 - accuracy: 0.9922 - val_loss: 0.4621 - val_accuracy: 0.7879\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.2138 - accuracy: 0.9922 - val_loss: 0.4592 - val_accuracy: 0.7879\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2100 - accuracy: 0.9922 - val_loss: 0.4354 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.2045 - accuracy: 0.9922 - val_loss: 0.4362 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2008 - accuracy: 0.9922 - val_loss: 0.4292 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.1971 - accuracy: 0.9922 - val_loss: 0.4239 - val_accuracy: 0.7879\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.1919 - accuracy: 0.9922 - val_loss: 0.4055 - val_accuracy: 0.7879\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.1872 - accuracy: 0.9922 - val_loss: 0.3929 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1829 - accuracy: 0.9922 - val_loss: 0.3960 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1798 - accuracy: 0.9922 - val_loss: 0.3898 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.1753 - accuracy: 0.9922 - val_loss: 0.3848 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.1721 - accuracy: 0.9922 - val_loss: 0.3907 - val_accuracy: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x283e7610dc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the GUR model \n",
    "grumodel = keras.Sequential([\n",
    "    keras.layers.GRU(256, input_shape=(1,753)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid), \n",
    "])\n",
    "\n",
    "#RMSprop, Adam, Adamax, Nadam\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "grumodel.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "grumodel.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1010c734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8439\n",
      "Valid accuracy: 0.8439153432846069\n",
      "AUC on validation set: 0.9337346024636057\n",
      "Sencitivity for GRU: 0.9308510638297872\n",
      "Specifity for GRU: 0.7578947368421053\n",
      "F1 score for GRU: 0.8557457212713936\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on validation set\n",
    "valid_loss_gru, valid_acc_gru =grumodel.evaluate(X_valid, y_valid)\n",
    "print('Valid accuracy:', valid_acc_gru)\n",
    "\n",
    "#for roc plot\n",
    "y_pre_gru = grumodel.predict(X_valid).ravel()\n",
    "fpr_gru, tpr_gru, thresholds_gru = roc_curve(y_valid, y_pre_gru)\n",
    "auc_gru = auc(fpr_gru, tpr_gru)\n",
    "print(\"AUC on validation set:\", auc_gru)\n",
    "\n",
    "#sensitivity, specificity and f1 score\n",
    "sen_gru, spe_gru, f1_gru = ss(X_valid, y_valid, grumodel)\n",
    "print(\"Sencitivity for GRU:\", sen_gru)\n",
    "print(\"Specifity for GRU:\", spe_gru)\n",
    "print(\"F1 score for GRU:\", f1_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b02b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6635459b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 6s 1s/step - loss: 0.6934 - accuracy: 0.5039 - val_loss: 0.6904 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6891 - accuracy: 0.7442 - val_loss: 0.6781 - val_accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6732 - accuracy: 0.4961 - val_loss: 0.6480 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6431 - accuracy: 0.5039 - val_loss: 0.6289 - val_accuracy: 0.5758\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6105 - accuracy: 0.6899 - val_loss: 0.6245 - val_accuracy: 0.6364\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5880 - accuracy: 0.8605 - val_loss: 0.5963 - val_accuracy: 0.7879\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5643 - accuracy: 0.8837 - val_loss: 0.5834 - val_accuracy: 0.8182\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5383 - accuracy: 0.9147 - val_loss: 0.5654 - val_accuracy: 0.8485\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5140 - accuracy: 0.9302 - val_loss: 0.5454 - val_accuracy: 0.8485\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4879 - accuracy: 0.9302 - val_loss: 0.5212 - val_accuracy: 0.8788\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4545 - accuracy: 0.9690 - val_loss: 0.5017 - val_accuracy: 0.9091\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4338 - accuracy: 0.9612 - val_loss: 0.5210 - val_accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4221 - accuracy: 0.9380 - val_loss: 0.4826 - val_accuracy: 0.8788\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3779 - accuracy: 0.9922 - val_loss: 0.4704 - val_accuracy: 0.8788\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3560 - accuracy: 0.9922 - val_loss: 0.4554 - val_accuracy: 0.8788\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.3371 - accuracy: 0.9922 - val_loss: 0.4443 - val_accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3183 - accuracy: 0.9922 - val_loss: 0.4424 - val_accuracy: 0.8788\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.2991 - accuracy: 0.9922 - val_loss: 0.4172 - val_accuracy: 0.9091\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2821 - accuracy: 0.9922 - val_loss: 0.4136 - val_accuracy: 0.8788\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2687 - accuracy: 0.9922 - val_loss: 0.4058 - val_accuracy: 0.8788\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2557 - accuracy: 0.9922 - val_loss: 0.3884 - val_accuracy: 0.9091\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2402 - accuracy: 0.9922 - val_loss: 0.3816 - val_accuracy: 0.9091\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.2261 - accuracy: 0.9922 - val_loss: 0.3738 - val_accuracy: 0.9091\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2137 - accuracy: 0.9922 - val_loss: 0.3701 - val_accuracy: 0.9091\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.2028 - accuracy: 0.9922 - val_loss: 0.3612 - val_accuracy: 0.9091\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.1904 - accuracy: 0.9922 - val_loss: 0.3562 - val_accuracy: 0.9091\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.1792 - accuracy: 0.9922 - val_loss: 0.3382 - val_accuracy: 0.9091\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.1688 - accuracy: 0.9922 - val_loss: 0.3444 - val_accuracy: 0.9091\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1608 - accuracy: 0.9922 - val_loss: 0.3444 - val_accuracy: 0.9091\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1545 - accuracy: 0.9922 - val_loss: 0.3332 - val_accuracy: 0.9091\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.1440 - accuracy: 0.9922 - val_loss: 0.4494 - val_accuracy: 0.8788\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.1391 - accuracy: 0.9922 - val_loss: 0.4224 - val_accuracy: 0.8788\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.1297 - accuracy: 0.9922 - val_loss: 0.4155 - val_accuracy: 0.8788\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1201 - accuracy: 0.9922 - val_loss: 0.4554 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.1190 - accuracy: 0.9845 - val_loss: 0.5254 - val_accuracy: 0.8182\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.2029 - accuracy: 0.9612 - val_loss: 0.3951 - val_accuracy: 0.8788\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.1100 - accuracy: 0.9922 - val_loss: 0.6599 - val_accuracy: 0.7576\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1853 - accuracy: 0.9457 - val_loss: 0.3757 - val_accuracy: 0.8788\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.1308 - accuracy: 0.9767 - val_loss: 0.4577 - val_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0941 - accuracy: 0.9922 - val_loss: 0.4228 - val_accuracy: 0.8485\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0908 - accuracy: 0.9922 - val_loss: 0.4315 - val_accuracy: 0.8485\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0855 - accuracy: 0.9922 - val_loss: 0.4288 - val_accuracy: 0.8485\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0809 - accuracy: 0.9922 - val_loss: 0.4284 - val_accuracy: 0.8485\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0742 - accuracy: 0.9922 - val_loss: 0.4309 - val_accuracy: 0.8485\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0720 - accuracy: 0.9922 - val_loss: 0.4633 - val_accuracy: 0.8485\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1016 - accuracy: 0.9922 - val_loss: 0.4030 - val_accuracy: 0.8788\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0569 - accuracy: 0.9922 - val_loss: 0.3959 - val_accuracy: 0.8788\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0543 - accuracy: 0.9922 - val_loss: 0.4014 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0516 - accuracy: 0.9922 - val_loss: 0.3968 - val_accuracy: 0.8485\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8485\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.8788\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8788\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.8788\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8788\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.8788\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9091\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.8788\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.8788\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9091\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9091\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9091\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9091\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9091\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9091\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8788\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.8788\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8788\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.8788\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.8788\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.8788\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.8788\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.8788\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.8788\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8485\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.8485\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.8485\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.8788\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.8788\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.8788\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.8788\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.8788\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.9091\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.8788\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.8788\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.8788\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.8788\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.8788\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 0.8788\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.8788\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6455 - val_accuracy: 0.8788\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.9091\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6444 - val_accuracy: 0.8788\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.9091\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.8788\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 0.8788\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6790 - val_accuracy: 0.9091\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.5477e-04 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8788\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 8.8215e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.8788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x283883ccd00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the LSTM model\n",
    "lstmmodel = keras.Sequential([\n",
    "    keras.layers.LSTM(256, input_shape=(1,753)),\n",
    "    keras.layers.Dense(64, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid), \n",
    "])\n",
    "\n",
    "#RMSprop, Adam, Adamax, Nadam\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "lstmmodel.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "lstmmodel.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a419d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7979 - accuracy: 0.8492\n",
      "Valid accuracy: 0.8492063283920288\n",
      "AUC on validation set: 0.9338605823068308\n",
      "Sencitivity for LSTM: 0.8776595744680851\n",
      "Specifity for LSTM: 0.8210526315789474\n",
      "F1 score for LSTM: 0.8527131782945737\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on validation set\n",
    "valid_loss_lstm, valid_acc_lstm = lstmmodel.evaluate(X_valid, y_valid)\n",
    "print('Valid accuracy:', valid_acc_lstm)\n",
    "\n",
    "#for roc plot\n",
    "y_pre_lstm = lstmmodel.predict(X_valid).ravel()\n",
    "fpr_lstm, tpr_lstm, thresholds_lstm = roc_curve(y_valid, y_pre_lstm)\n",
    "auc_lstm = auc(fpr_lstm, tpr_lstm)\n",
    "print(\"AUC on validation set:\", auc_lstm)\n",
    "\n",
    "#sensitivity, specificity and f1 score\n",
    "sen_lstm, spe_lstm, f1_lstm = ss(X_valid, y_valid, lstmmodel)\n",
    "print(\"Sencitivity for LSTM:\", sen_lstm)\n",
    "print(\"Specifity for LSTM:\", spe_lstm)\n",
    "print(\"F1 score for LSTM:\", f1_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffed2a",
   "metadata": {},
   "source": [
    "There is one main problem with deep learning models, all of the three models are not robust enough, possible reasons are:\n",
    "\n",
    "(1) The dataset is not large enough to train a powerful and robust deep learning model;\n",
    "\n",
    "(2) There are too many hyperparameters in these three models, and it takes time to do a grid search to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0e7bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted output\n",
    "pred_lstm = lstmmodel.predict(X_test)\n",
    "for i in pred_lstm:\n",
    "    if i[0]>0.5:\n",
    "        i[0] = 1\n",
    "    else:\n",
    "        i[0] = 0\n",
    "df_test['pred']=pred_lstm\n",
    "df_out = df_test[['id','pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42c5c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('Group8_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9533a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c78392dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_nn, tpr_nn, label='Neural Netwrok (auc = {:.3f})'.format(auc_nn))\n",
    "plt.plot(fpr_gru, tpr_gru, label='GRU (auc = {:.3f})'.format(auc_gru))\n",
    "plt.plot(fpr_lstm, tpr_lstm, label='LSTM (auc = {:.3f})'.format(auc_lstm))\n",
    "plt.xlabel('Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61c446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
