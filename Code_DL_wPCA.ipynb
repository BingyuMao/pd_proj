{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3079f6a",
   "metadata": {},
   "source": [
    "## Deep learning models\n",
    "#### Import packages, load data and define necussary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3bad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c47b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read the training dataset after resampling and standardization\n",
    "df = pd.read_csv('train_scaled.pca.csv')\n",
    "\n",
    "#remove class and id\n",
    "features = list(df.columns.values)\n",
    "features.remove('class')\n",
    "features.remove('id')\n",
    "\n",
    "X = df[features]\n",
    "y = df['class']\n",
    "#split to train and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.7)\n",
    "\n",
    "#set up the test set\n",
    "df_test = pd.read_csv('test_scaled.csv')\n",
    "features_test = list(df_test.columns.values)\n",
    "features_test.remove('class')\n",
    "features_test.remove('id')\n",
    "\n",
    "X_test = df_test[features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a5d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function for sensitivity, specificity and f1 score\n",
    "def ss(X, y, m):\n",
    "    cm = confusion_matrix(y, np.rint(m.predict(X)))\n",
    "    sen = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "    spe = cm[1][1] / (cm[1][0] + cm[1][1])\n",
    "    prec = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "    f1 = 2 * prec * sen / (prec + sen)\n",
    "    return sen, spe, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448115e",
   "metadata": {},
   "source": [
    "#### Define and train the data on three different models\n",
    "\n",
    "The first model is a simple neural network with regular densely-connected NN layers. The second model is GRU (a type of RNN model) and the third model is another RNN model called LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8611f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2/2 [==============================] - 2s 515ms/step - loss: 0.7315 - accuracy: 0.6082 - val_loss: 1.0709 - val_accuracy: 0.5200\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4869 - accuracy: 0.7835 - val_loss: 0.7972 - val_accuracy: 0.5600\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2730 - accuracy: 0.8763 - val_loss: 0.7480 - val_accuracy: 0.6000\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1965 - accuracy: 0.9485 - val_loss: 0.7487 - val_accuracy: 0.7600\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.1127 - accuracy: 0.9588 - val_loss: 0.8103 - val_accuracy: 0.7600\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0718 - accuracy: 0.9897 - val_loss: 0.8808 - val_accuracy: 0.7600\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0554 - accuracy: 0.9897 - val_loss: 0.9737 - val_accuracy: 0.7600\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0424 - accuracy: 0.9897 - val_loss: 1.0628 - val_accuracy: 0.7600\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 1.1424 - val_accuracy: 0.7600\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 1.2166 - val_accuracy: 0.7600\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0247 - accuracy: 0.9897 - val_loss: 1.2859 - val_accuracy: 0.7600\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0198 - accuracy: 0.9897 - val_loss: 1.3568 - val_accuracy: 0.7600\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0129 - accuracy: 0.9897 - val_loss: 1.4308 - val_accuracy: 0.7600\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.5004 - val_accuracy: 0.7600\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5678 - val_accuracy: 0.7200\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6300 - val_accuracy: 0.7200\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.6839 - val_accuracy: 0.7200\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7269 - val_accuracy: 0.7200\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.7609 - val_accuracy: 0.7200\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7865 - val_accuracy: 0.7200\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8071 - val_accuracy: 0.7200\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8237 - val_accuracy: 0.7200\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8369 - val_accuracy: 0.7200\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8468 - val_accuracy: 0.7200\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8554 - val_accuracy: 0.7200\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8627 - val_accuracy: 0.7200\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9.8726e-04 - accuracy: 1.0000 - val_loss: 1.8693 - val_accuracy: 0.7200\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9.1241e-04 - accuracy: 1.0000 - val_loss: 1.8757 - val_accuracy: 0.7200\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 8.3127e-04 - accuracy: 1.0000 - val_loss: 1.8809 - val_accuracy: 0.7200\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 7.6552e-04 - accuracy: 1.0000 - val_loss: 1.8856 - val_accuracy: 0.7200\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.2455e-04 - accuracy: 1.0000 - val_loss: 1.8900 - val_accuracy: 0.7200\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.7321e-04 - accuracy: 1.0000 - val_loss: 1.8943 - val_accuracy: 0.7200\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 6.4137e-04 - accuracy: 1.0000 - val_loss: 1.8986 - val_accuracy: 0.7200\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6.0632e-04 - accuracy: 1.0000 - val_loss: 1.9030 - val_accuracy: 0.7200\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 5.7771e-04 - accuracy: 1.0000 - val_loss: 1.9074 - val_accuracy: 0.7200\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.5401e-04 - accuracy: 1.0000 - val_loss: 1.9116 - val_accuracy: 0.7200\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 5.2692e-04 - accuracy: 1.0000 - val_loss: 1.9157 - val_accuracy: 0.7200\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.0785e-04 - accuracy: 1.0000 - val_loss: 1.9200 - val_accuracy: 0.7200\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 4.8876e-04 - accuracy: 1.0000 - val_loss: 1.9242 - val_accuracy: 0.7200\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.7307e-04 - accuracy: 1.0000 - val_loss: 1.9283 - val_accuracy: 0.7200\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.5674e-04 - accuracy: 1.0000 - val_loss: 1.9325 - val_accuracy: 0.7200\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 4.4244e-04 - accuracy: 1.0000 - val_loss: 1.9365 - val_accuracy: 0.7200\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 4.2877e-04 - accuracy: 1.0000 - val_loss: 1.9404 - val_accuracy: 0.7200\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.1664e-04 - accuracy: 1.0000 - val_loss: 1.9443 - val_accuracy: 0.7200\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.0468e-04 - accuracy: 1.0000 - val_loss: 1.9484 - val_accuracy: 0.7200\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.9499e-04 - accuracy: 1.0000 - val_loss: 1.9526 - val_accuracy: 0.7200\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.8436e-04 - accuracy: 1.0000 - val_loss: 1.9567 - val_accuracy: 0.7200\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7514e-04 - accuracy: 1.0000 - val_loss: 1.9609 - val_accuracy: 0.7200\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.6600e-04 - accuracy: 1.0000 - val_loss: 1.9650 - val_accuracy: 0.7200\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.5720e-04 - accuracy: 1.0000 - val_loss: 1.9689 - val_accuracy: 0.7200\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.4948e-04 - accuracy: 1.0000 - val_loss: 1.9730 - val_accuracy: 0.7200\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.4152e-04 - accuracy: 1.0000 - val_loss: 1.9771 - val_accuracy: 0.7200\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.3457e-04 - accuracy: 1.0000 - val_loss: 1.9811 - val_accuracy: 0.7200\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.2704e-04 - accuracy: 1.0000 - val_loss: 1.9848 - val_accuracy: 0.7200\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.2071e-04 - accuracy: 1.0000 - val_loss: 1.9883 - val_accuracy: 0.7200\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.1390e-04 - accuracy: 1.0000 - val_loss: 1.9916 - val_accuracy: 0.7200\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.0720e-04 - accuracy: 1.0000 - val_loss: 1.9949 - val_accuracy: 0.7200\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 58ms/step - loss: 3.0146e-04 - accuracy: 1.0000 - val_loss: 1.9983 - val_accuracy: 0.7200\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.9499e-04 - accuracy: 1.0000 - val_loss: 2.0020 - val_accuracy: 0.7200\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.8965e-04 - accuracy: 1.0000 - val_loss: 2.0057 - val_accuracy: 0.7200\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.8392e-04 - accuracy: 1.0000 - val_loss: 2.0095 - val_accuracy: 0.7200\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.7879e-04 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.7200\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.7361e-04 - accuracy: 1.0000 - val_loss: 2.0166 - val_accuracy: 0.7200\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.6863e-04 - accuracy: 1.0000 - val_loss: 2.0198 - val_accuracy: 0.7200\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2.6316e-04 - accuracy: 1.0000 - val_loss: 2.0230 - val_accuracy: 0.7200\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.5854e-04 - accuracy: 1.0000 - val_loss: 2.0261 - val_accuracy: 0.7200\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.5421e-04 - accuracy: 1.0000 - val_loss: 2.0290 - val_accuracy: 0.7200\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.4997e-04 - accuracy: 1.0000 - val_loss: 2.0319 - val_accuracy: 0.7200\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2.4522e-04 - accuracy: 1.0000 - val_loss: 2.0349 - val_accuracy: 0.7200\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.4190e-04 - accuracy: 1.0000 - val_loss: 2.0377 - val_accuracy: 0.7200\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 2.3787e-04 - accuracy: 1.0000 - val_loss: 2.0403 - val_accuracy: 0.7200\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 2.3406e-04 - accuracy: 1.0000 - val_loss: 2.0428 - val_accuracy: 0.7200\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.3045e-04 - accuracy: 1.0000 - val_loss: 2.0454 - val_accuracy: 0.7200\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.2716e-04 - accuracy: 1.0000 - val_loss: 2.0478 - val_accuracy: 0.7200\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.2337e-04 - accuracy: 1.0000 - val_loss: 2.0503 - val_accuracy: 0.7200\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 2.2057e-04 - accuracy: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.7200\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.1748e-04 - accuracy: 1.0000 - val_loss: 2.0549 - val_accuracy: 0.7200\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.1411e-04 - accuracy: 1.0000 - val_loss: 2.0571 - val_accuracy: 0.7200\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.1111e-04 - accuracy: 1.0000 - val_loss: 2.0592 - val_accuracy: 0.7200\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 2.0826e-04 - accuracy: 1.0000 - val_loss: 2.0614 - val_accuracy: 0.7200\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2.0535e-04 - accuracy: 1.0000 - val_loss: 2.0636 - val_accuracy: 0.7200\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.0259e-04 - accuracy: 1.0000 - val_loss: 2.0658 - val_accuracy: 0.7200\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.9974e-04 - accuracy: 1.0000 - val_loss: 2.0683 - val_accuracy: 0.7200\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.9713e-04 - accuracy: 1.0000 - val_loss: 2.0708 - val_accuracy: 0.7200\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9473e-04 - accuracy: 1.0000 - val_loss: 2.0732 - val_accuracy: 0.7200\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.9202e-04 - accuracy: 1.0000 - val_loss: 2.0753 - val_accuracy: 0.7200\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.8955e-04 - accuracy: 1.0000 - val_loss: 2.0775 - val_accuracy: 0.7200\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.8734e-04 - accuracy: 1.0000 - val_loss: 2.0797 - val_accuracy: 0.7200\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.8495e-04 - accuracy: 1.0000 - val_loss: 2.0816 - val_accuracy: 0.7200\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.8255e-04 - accuracy: 1.0000 - val_loss: 2.0835 - val_accuracy: 0.7200\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.8033e-04 - accuracy: 1.0000 - val_loss: 2.0856 - val_accuracy: 0.7200\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.7824e-04 - accuracy: 1.0000 - val_loss: 2.0876 - val_accuracy: 0.7200\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.7581e-04 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.7200\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.7406e-04 - accuracy: 1.0000 - val_loss: 2.0919 - val_accuracy: 0.7200\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.7191e-04 - accuracy: 1.0000 - val_loss: 2.0940 - val_accuracy: 0.7200\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.7008e-04 - accuracy: 1.0000 - val_loss: 2.0959 - val_accuracy: 0.7200\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.6783e-04 - accuracy: 1.0000 - val_loss: 2.0978 - val_accuracy: 0.7200\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.6612e-04 - accuracy: 1.0000 - val_loss: 2.0997 - val_accuracy: 0.7200\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.6426e-04 - accuracy: 1.0000 - val_loss: 2.1016 - val_accuracy: 0.7200\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.6249e-04 - accuracy: 1.0000 - val_loss: 2.1037 - val_accuracy: 0.7200\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.6078e-04 - accuracy: 1.0000 - val_loss: 2.1057 - val_accuracy: 0.7200\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.5883e-04 - accuracy: 1.0000 - val_loss: 2.1077 - val_accuracy: 0.7200\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.5735e-04 - accuracy: 1.0000 - val_loss: 2.1097 - val_accuracy: 0.7200\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.5554e-04 - accuracy: 1.0000 - val_loss: 2.1118 - val_accuracy: 0.7200\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.5402e-04 - accuracy: 1.0000 - val_loss: 2.1137 - val_accuracy: 0.7200\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.5249e-04 - accuracy: 1.0000 - val_loss: 2.1158 - val_accuracy: 0.7200\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.5058e-04 - accuracy: 1.0000 - val_loss: 2.1177 - val_accuracy: 0.7200\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.4915e-04 - accuracy: 1.0000 - val_loss: 2.1196 - val_accuracy: 0.7200\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.4777e-04 - accuracy: 1.0000 - val_loss: 2.1215 - val_accuracy: 0.7200\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.4604e-04 - accuracy: 1.0000 - val_loss: 2.1235 - val_accuracy: 0.7200\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.4461e-04 - accuracy: 1.0000 - val_loss: 2.1255 - val_accuracy: 0.7200\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.4324e-04 - accuracy: 1.0000 - val_loss: 2.1274 - val_accuracy: 0.7200\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.4164e-04 - accuracy: 1.0000 - val_loss: 2.1292 - val_accuracy: 0.7200\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 66ms/step - loss: 1.4031e-04 - accuracy: 1.0000 - val_loss: 2.1309 - val_accuracy: 0.7200\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.3889e-04 - accuracy: 1.0000 - val_loss: 2.1327 - val_accuracy: 0.7200\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.3757e-04 - accuracy: 1.0000 - val_loss: 2.1345 - val_accuracy: 0.7200\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.3610e-04 - accuracy: 1.0000 - val_loss: 2.1362 - val_accuracy: 0.7200\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.3480e-04 - accuracy: 1.0000 - val_loss: 2.1378 - val_accuracy: 0.7200\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.3354e-04 - accuracy: 1.0000 - val_loss: 2.1394 - val_accuracy: 0.7200\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.3216e-04 - accuracy: 1.0000 - val_loss: 2.1411 - val_accuracy: 0.7200\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.3100e-04 - accuracy: 1.0000 - val_loss: 2.1427 - val_accuracy: 0.7200\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2977e-04 - accuracy: 1.0000 - val_loss: 2.1442 - val_accuracy: 0.7200\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.2844e-04 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.7200\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.2738e-04 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.7200\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.2605e-04 - accuracy: 1.0000 - val_loss: 2.1489 - val_accuracy: 0.7200\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.2502e-04 - accuracy: 1.0000 - val_loss: 2.1504 - val_accuracy: 0.7200\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2382e-04 - accuracy: 1.0000 - val_loss: 2.1520 - val_accuracy: 0.7200\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2263e-04 - accuracy: 1.0000 - val_loss: 2.1536 - val_accuracy: 0.7200\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2174e-04 - accuracy: 1.0000 - val_loss: 2.1552 - val_accuracy: 0.7200\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.2050e-04 - accuracy: 1.0000 - val_loss: 2.1569 - val_accuracy: 0.7200\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1959e-04 - accuracy: 1.0000 - val_loss: 2.1583 - val_accuracy: 0.7200\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.1854e-04 - accuracy: 1.0000 - val_loss: 2.1598 - val_accuracy: 0.7200\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1753e-04 - accuracy: 1.0000 - val_loss: 2.1614 - val_accuracy: 0.7200\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1648e-04 - accuracy: 1.0000 - val_loss: 2.1630 - val_accuracy: 0.7200\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1542e-04 - accuracy: 1.0000 - val_loss: 2.1645 - val_accuracy: 0.7200\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1445e-04 - accuracy: 1.0000 - val_loss: 2.1661 - val_accuracy: 0.7200\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.1348e-04 - accuracy: 1.0000 - val_loss: 2.1677 - val_accuracy: 0.7200\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1255e-04 - accuracy: 1.0000 - val_loss: 2.1693 - val_accuracy: 0.7200\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1164e-04 - accuracy: 1.0000 - val_loss: 2.1709 - val_accuracy: 0.7200\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1065e-04 - accuracy: 1.0000 - val_loss: 2.1725 - val_accuracy: 0.7200\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: 2.1741 - val_accuracy: 0.7200\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0885e-04 - accuracy: 1.0000 - val_loss: 2.1756 - val_accuracy: 0.7200\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0799e-04 - accuracy: 1.0000 - val_loss: 2.1771 - val_accuracy: 0.7200\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.0703e-04 - accuracy: 1.0000 - val_loss: 2.1786 - val_accuracy: 0.7200\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0623e-04 - accuracy: 1.0000 - val_loss: 2.1800 - val_accuracy: 0.7200\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0527e-04 - accuracy: 1.0000 - val_loss: 2.1815 - val_accuracy: 0.7200\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0450e-04 - accuracy: 1.0000 - val_loss: 2.1830 - val_accuracy: 0.7200\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0365e-04 - accuracy: 1.0000 - val_loss: 2.1846 - val_accuracy: 0.7200\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0275e-04 - accuracy: 1.0000 - val_loss: 2.1862 - val_accuracy: 0.7200\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.0197e-04 - accuracy: 1.0000 - val_loss: 2.1878 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2124d62eb20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the model\n",
    "#this is a Neural Network which four layers. \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(40,)), #confirm the input shape\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu), \n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid), \n",
    "])\n",
    "\n",
    "#RMSprop, Adam, Adamax, Nadam\n",
    "opt = keras.optimizers.Adamax(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9607bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.9552 - accuracy: 0.8427\n",
      "Valid accuracy: 0.8426573276519775\n",
      "AUC on validation set: 0.9181867083964986\n",
      "Sencitivity for neural network: 0.9090909090909091\n",
      "Specifity for neural network: 0.7762237762237763\n",
      "F1 score for neural network: 0.8524590163934426\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on validation set\n",
    "valid_loss_nn, valid_acc_nn = model.evaluate(X_valid, y_valid)\n",
    "print('Valid accuracy:', valid_acc_nn)\n",
    "\n",
    "#for roc plot\n",
    "y_pre_nn = model.predict(X_valid).ravel()\n",
    "fpr_nn, tpr_nn, thresholds_nn = roc_curve(y_valid, y_pre_nn)\n",
    "auc_nn = auc(fpr_nn, tpr_nn)\n",
    "print(\"AUC on validation set:\", auc_nn)\n",
    "\n",
    "#sensitivity, specificity and f1 score\n",
    "sen_nn, spe_nn, f1_nn = ss(X_valid, y_valid, model)\n",
    "print(\"Sencitivity for neural network:\", sen_nn)\n",
    "print(\"Specifity for neural network:\", spe_nn)\n",
    "print(\"F1 score for neural network:\", f1_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a15dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadb8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 1, 40)\n",
    "X_valid = X_valid.values.reshape(-1, 1, 40)\n",
    "X_test  = X_test.values.reshape(-1, 1, 753)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d84706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6927 - accuracy: 0.7113 - val_loss: 0.6914 - val_accuracy: 0.7200\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6901 - accuracy: 0.7526 - val_loss: 0.6905 - val_accuracy: 0.5200\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6866 - accuracy: 0.7938 - val_loss: 0.6881 - val_accuracy: 0.6800\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6828 - accuracy: 0.8454 - val_loss: 0.6871 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6773 - accuracy: 0.8247 - val_loss: 0.6841 - val_accuracy: 0.6400\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6714 - accuracy: 0.9072 - val_loss: 0.6825 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6646 - accuracy: 0.9278 - val_loss: 0.6793 - val_accuracy: 0.6400\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6572 - accuracy: 0.9278 - val_loss: 0.6769 - val_accuracy: 0.5600\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6492 - accuracy: 0.9278 - val_loss: 0.6738 - val_accuracy: 0.5600\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6405 - accuracy: 0.9278 - val_loss: 0.6710 - val_accuracy: 0.5600\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6314 - accuracy: 0.9278 - val_loss: 0.6677 - val_accuracy: 0.6400\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6219 - accuracy: 0.9485 - val_loss: 0.6650 - val_accuracy: 0.6400\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6122 - accuracy: 0.9485 - val_loss: 0.6615 - val_accuracy: 0.6400\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6026 - accuracy: 0.9485 - val_loss: 0.6591 - val_accuracy: 0.6400\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5924 - accuracy: 0.9588 - val_loss: 0.6555 - val_accuracy: 0.6400\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5825 - accuracy: 0.9588 - val_loss: 0.6526 - val_accuracy: 0.6400\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5721 - accuracy: 0.9588 - val_loss: 0.6488 - val_accuracy: 0.6400\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5621 - accuracy: 0.9588 - val_loss: 0.6468 - val_accuracy: 0.6400\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5522 - accuracy: 0.9691 - val_loss: 0.6434 - val_accuracy: 0.6400\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5424 - accuracy: 0.9691 - val_loss: 0.6413 - val_accuracy: 0.6400\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5321 - accuracy: 0.9691 - val_loss: 0.6385 - val_accuracy: 0.6400\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5222 - accuracy: 0.9691 - val_loss: 0.6365 - val_accuracy: 0.6400\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5123 - accuracy: 0.9691 - val_loss: 0.6333 - val_accuracy: 0.6400\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5025 - accuracy: 0.9691 - val_loss: 0.6313 - val_accuracy: 0.6400\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4927 - accuracy: 0.9691 - val_loss: 0.6286 - val_accuracy: 0.6400\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4830 - accuracy: 0.9691 - val_loss: 0.6267 - val_accuracy: 0.6400\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4734 - accuracy: 0.9691 - val_loss: 0.6246 - val_accuracy: 0.6400\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4639 - accuracy: 0.9691 - val_loss: 0.6230 - val_accuracy: 0.6400\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4541 - accuracy: 0.9691 - val_loss: 0.6213 - val_accuracy: 0.6400\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4446 - accuracy: 0.9794 - val_loss: 0.6193 - val_accuracy: 0.6800\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4351 - accuracy: 0.9794 - val_loss: 0.6174 - val_accuracy: 0.6800\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4257 - accuracy: 0.9897 - val_loss: 0.6156 - val_accuracy: 0.6800\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4165 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.6800\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4075 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.6800\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3988 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.6800\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3899 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.6800\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3813 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.6800\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3730 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.6800\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3647 - accuracy: 1.0000 - val_loss: 0.6086 - val_accuracy: 0.6800\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3568 - accuracy: 1.0000 - val_loss: 0.6074 - val_accuracy: 0.6800\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3490 - accuracy: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.6800\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3416 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.6800\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3344 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.6800\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3268 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.6800\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3196 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.6800\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3127 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.6800\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3059 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.6800\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2993 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.6800\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2927 - accuracy: 1.0000 - val_loss: 0.6031 - val_accuracy: 0.6800\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2864 - accuracy: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.6800\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2800 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.6800\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2741 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.6800\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2676 - accuracy: 1.0000 - val_loss: 0.6006 - val_accuracy: 0.6800\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2613 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.6800\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2550 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.6800\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2488 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.6800\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.6800\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2376 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.6800\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2329 - accuracy: 1.0000 - val_loss: 0.6022 - val_accuracy: 0.6800\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2267 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.6800\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.6800\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.6800\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.6800\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.6800\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2014 - accuracy: 1.0000 - val_loss: 0.6110 - val_accuracy: 0.6800\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1974 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.6800\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1919 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.6800\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1873 - accuracy: 1.0000 - val_loss: 0.6180 - val_accuracy: 0.6800\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1831 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.6800\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 0.7200\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1764 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.7200\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1711 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.7200\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1665 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.7200\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1625 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.7200\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1587 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.7200\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1555 - accuracy: 1.0000 - val_loss: 0.6435 - val_accuracy: 0.7200\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.7200\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1486 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 0.7200\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.7200\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1409 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.7200\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1372 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.7200\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1345 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.7200\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.7200\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.7200\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 0.6768 - val_accuracy: 0.7200\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.7200\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1182 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.7200\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.7200\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.7200\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1104 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.7200\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.7200\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.7200\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.7200\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.7200\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.7200\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.7232 - val_accuracy: 0.7200\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.7200\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0892 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.7200\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.7200\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2124cd51220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the GUR model \n",
    "grumodel = keras.Sequential([\n",
    "    keras.layers.GRU(256, input_shape=(1,40)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid), \n",
    "])\n",
    "\n",
    "#RMSprop, Adam, Adamax, Nadam\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "grumodel.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "grumodel.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1010c734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.8252\n",
      "Valid accuracy: 0.8251748085021973\n",
      "AUC on validation set: 0.9182356105433029\n",
      "Sencitivity for GRU: 0.9300699300699301\n",
      "Specifity for GRU: 0.7202797202797203\n",
      "F1 score for GRU: 0.8417721518987342\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on validation set\n",
    "valid_loss_gru, valid_acc_gru =grumodel.evaluate(X_valid, y_valid)\n",
    "print('Valid accuracy:', valid_acc_gru)\n",
    "\n",
    "#for roc plot\n",
    "y_pre_gru = grumodel.predict(X_valid).ravel()\n",
    "fpr_gru, tpr_gru, thresholds_gru = roc_curve(y_valid, y_pre_gru)\n",
    "auc_gru = auc(fpr_gru, tpr_gru)\n",
    "print(\"AUC on validation set:\", auc_gru)\n",
    "\n",
    "#sensitivity, specificity and f1 score\n",
    "sen_gru, spe_gru, f1_gru = ss(X_valid, y_valid, grumodel)\n",
    "print(\"Sencitivity for GRU:\", sen_gru)\n",
    "print(\"Specifity for GRU:\", spe_gru)\n",
    "print(\"F1 score for GRU:\", f1_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b02b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6635459b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6934 - accuracy: 0.4948 - val_loss: 0.6910 - val_accuracy: 0.4800\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6869 - accuracy: 0.5052 - val_loss: 0.6660 - val_accuracy: 0.6400\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6406 - accuracy: 0.9175 - val_loss: 0.6539 - val_accuracy: 0.5600\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5684 - accuracy: 0.9485 - val_loss: 0.6412 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5009 - accuracy: 0.9794 - val_loss: 0.6327 - val_accuracy: 0.6800\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4496 - accuracy: 0.9897 - val_loss: 0.6004 - val_accuracy: 0.7200\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4045 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.7200\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3641 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.7200\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3283 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.7600\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2990 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.7200\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2735 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.7200\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2535 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.7200\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2337 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.7200\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.7200\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2033 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.7200\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1891 - accuracy: 1.0000 - val_loss: 0.5962 - val_accuracy: 0.7200\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1772 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.7200\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.7200\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1552 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 0.7200\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1451 - accuracy: 1.0000 - val_loss: 0.6261 - val_accuracy: 0.7200\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.7200\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1287 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.7200\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1204 - accuracy: 1.0000 - val_loss: 0.6554 - val_accuracy: 0.7200\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.7200\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1070 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.7200\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.6838 - val_accuracy: 0.7200\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.7200\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.7200\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.7200\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.7200\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.7200\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.7476 - val_accuracy: 0.7200\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.7595 - val_accuracy: 0.7200\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.7200\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.7200\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.7200\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.7200\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.7200\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.7200\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.8403 - val_accuracy: 0.7200\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.8500 - val_accuracy: 0.7200\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.8626 - val_accuracy: 0.7200\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.8756 - val_accuracy: 0.7200\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.8870 - val_accuracy: 0.7200\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.7200\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.7200\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.9241 - val_accuracy: 0.7200\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.9343 - val_accuracy: 0.7200\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.9475 - val_accuracy: 0.7200\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.7200\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.7200\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.7200\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.9983 - val_accuracy: 0.7200\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.7200\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.7200\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 0.7200\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.7200\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.7200\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.0718 - val_accuracy: 0.7200\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 0.7200\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.7200\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.1117 - val_accuracy: 0.7200\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.1233 - val_accuracy: 0.7200\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1362 - val_accuracy: 0.7200\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.1488 - val_accuracy: 0.7200\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.7200\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.1741 - val_accuracy: 0.7200\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.1852 - val_accuracy: 0.7200\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.2002 - val_accuracy: 0.7200\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.2110 - val_accuracy: 0.7200\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.2253 - val_accuracy: 0.7200\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2372 - val_accuracy: 0.7200\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.7200\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.7200\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2757 - val_accuracy: 0.7200\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2887 - val_accuracy: 0.7200\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.3016 - val_accuracy: 0.7200\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.7200\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3277 - val_accuracy: 0.7200\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.3398 - val_accuracy: 0.7200\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.3513 - val_accuracy: 0.7200\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.3642 - val_accuracy: 0.7200\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.7200\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3909 - val_accuracy: 0.7200\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4033 - val_accuracy: 0.7200\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4149 - val_accuracy: 0.7200\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4300 - val_accuracy: 0.7200\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4425 - val_accuracy: 0.7200\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4538 - val_accuracy: 0.7200\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4676 - val_accuracy: 0.7200\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4814 - val_accuracy: 0.7200\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4941 - val_accuracy: 0.7200\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5052 - val_accuracy: 0.7200\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.5191 - val_accuracy: 0.7200\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5316 - val_accuracy: 0.7200\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.5457 - val_accuracy: 0.7200\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5570 - val_accuracy: 0.7200\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5693 - val_accuracy: 0.7200\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5839 - val_accuracy: 0.7200\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5973 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21257a0ca90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the LSTM model\n",
    "lstmmodel = keras.Sequential([\n",
    "    keras.layers.LSTM(256, input_shape=(1,40)),\n",
    "    keras.layers.Dense(64, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid), \n",
    "])\n",
    "\n",
    "#RMSprop, Adam, Adamax, Nadam\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "lstmmodel.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "lstmmodel.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a419d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8485 - accuracy: 0.8392\n",
      "Valid accuracy: 0.8391608595848083\n",
      "AUC on validation set: 0.9148124602670057\n",
      "Sencitivity for LSTM: 0.8951048951048951\n",
      "Specifity for LSTM: 0.7832167832167832\n",
      "F1 score for LSTM: 0.847682119205298\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on validation set\n",
    "valid_loss_lstm, valid_acc_lstm = lstmmodel.evaluate(X_valid, y_valid)\n",
    "print('Valid accuracy:', valid_acc_lstm)\n",
    "\n",
    "#for roc plot\n",
    "y_pre_lstm = lstmmodel.predict(X_valid).ravel()\n",
    "fpr_lstm, tpr_lstm, thresholds_lstm = roc_curve(y_valid, y_pre_lstm)\n",
    "auc_lstm = auc(fpr_lstm, tpr_lstm)\n",
    "print(\"AUC on validation set:\", auc_lstm)\n",
    "\n",
    "#sensitivity, specificity and f1 score\n",
    "sen_lstm, spe_lstm, f1_lstm = ss(X_valid, y_valid, lstmmodel)\n",
    "print(\"Sencitivity for LSTM:\", sen_lstm)\n",
    "print(\"Specifity for LSTM:\", spe_lstm)\n",
    "print(\"F1 score for LSTM:\", f1_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffed2a",
   "metadata": {},
   "source": [
    "There is one main problem with deep learning models, all of the three models are not robust enough, possible reasons are:\n",
    "\n",
    "(1) The dataset is not large enough to train a powerful and robust deep learning model;\n",
    "\n",
    "(2) There are too many hyperparameters in these three models, and it takes time to do a grid search to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78392dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_nn, tpr_nn, label='Neural Netwrok (auc = {:.3f})'.format(auc_nn))\n",
    "plt.plot(fpr_gru, tpr_gru, label='GRU (auc = {:.3f})'.format(auc_gru))\n",
    "plt.plot(fpr_lstm, tpr_lstm, label='LSTM (auc = {:.3f})'.format(auc_lstm))\n",
    "plt.xlabel('Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61c446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
